# ç›‘æ§ä¸å¯è§‚æµ‹æ€§æŒ‡å—

> å…³é”®ä¸å˜é‡ï¼šRED/USE æŒ‡æ ‡åˆ†å±‚è½åœ°ï¼›è¿½è¸ªä¸æ—¥å¿—ä¸Šä¸‹æ–‡å…³è”ï¼›é‡‡æ ·ä¼˜å…ˆä¿ç•™é”™è¯¯/æ…¢è°ƒç”¨ã€‚

æœ¬æ–‡æ¡£æä¾›äº†åˆ†å¸ƒå¼ç³»ç»Ÿç›‘æ§ä¸å¯è§‚æµ‹æ€§çš„å…¨é¢æŒ‡å—ï¼ŒåŒ…æ‹¬æŒ‡æ ‡æ”¶é›†ã€æ—¥å¿—èšåˆã€é“¾è·¯è¿½è¸ªå’Œå‘Šè­¦ç³»ç»Ÿã€‚

## ğŸ¯ å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±

### 1. æŒ‡æ ‡ (Metrics)

- **RED æŒ‡æ ‡**: è¯·æ±‚ç‡ (Rate)ã€é”™è¯¯ç‡ (Error)ã€æŒç»­æ—¶é—´ (Duration)
- **USE æŒ‡æ ‡**: åˆ©ç”¨ç‡ (Utilization)ã€é¥±å’Œåº¦ (Saturation)ã€é”™è¯¯ç‡ (Error)

> é€‰æ‹©æŒ‡å¼•ï¼šé¢å‘å¤–éƒ¨æ¥å£ä»¥ RED ä¸ºä¸»ã€é¢å‘ç³»ç»Ÿèµ„æºä»¥ USE ä¸ºä¸»ï¼›ä¸¤è€…äº’è¡¥ã€‚

#### åˆ†å±‚æŒ‡æ ‡å»ºè®®

- RPC å±‚ï¼š`rpc.requests`, `rpc.errors`, `rpc.latency.ms{op}`
- å…±è¯†å±‚ï¼š`raft.append.entries`, `raft.commit.index`, `raft.leader.elections`
- å¤åˆ¶å±‚ï¼š`replica.acks`, `replica.lag.ms`, `replica.repair.count`
- å­˜å‚¨å±‚ï¼š`wal.fsync.ms`, `snapshot.bytes`, `segment.crc.errors`
- è¡¥å¿å±‚ï¼š`saga.steps`, `saga.compensate.count`, `saga.failure.matrix{kind}`

ä»ªè¡¨è®¾è®¡å»ºè®®ï¼š

- ä¸º P50/P95/P99 å»¶è¿Ÿä½¿ç”¨ç›´æ–¹å›¾æ¡¶ï¼ŒåŒºåˆ†è¯»å–/å†™å…¥/å…±è¯†è·¯å¾„ï¼›æ ‡ç­¾ç»´åº¦å—æ§ï¼Œé¿å…é«˜åŸºæ•°ã€‚

### 2. æ—¥å¿— (Logs)

- **ç»“æ„åŒ–æ—¥å¿—**: ä½¿ç”¨ JSON æ ¼å¼ï¼Œä¾¿äºè§£æå’ŒæŸ¥è¯¢
- **æ—¥å¿—çº§åˆ«**: Trace, Debug, Info, Warn, Error, Fatal
- **ä¸Šä¸‹æ–‡ä¿¡æ¯**: åŒ…å« trace_id, span_id, user_id ç­‰
  - ä¸è¿½è¸ªå…³è”ï¼šåœ¨æ—¥å¿—æ¡ç›®ä¸­æ³¨å…¥ trace/span ä¸Šä¸‹æ–‡ï¼Œä¾¿äºè·¨ç³»ç»Ÿæ’éšœã€‚

### 3. é“¾è·¯è¿½è¸ª (Tracing)

- **åˆ†å¸ƒå¼è¿½è¸ª**: è·¨æœåŠ¡è°ƒç”¨é“¾è¿½è¸ª
- **æ€§èƒ½åˆ†æ**: è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œçƒ­ç‚¹
- **é”™è¯¯å®šä½**: å¿«é€Ÿå®šä½é”™è¯¯æ ¹æº
  - é‡‡æ ·ç­–ç•¥ï¼šä¼˜å…ˆä¿ç•™é”™è¯¯ä¸æ…¢è°ƒç”¨ï¼Œé™ä½ä½ä»·å€¼æµé‡ï¼›å¯¼å‡ºä¸å­˜å‚¨éµå¾ªæ•°æ®ä¿ç•™ç­–ç•¥ã€‚

## ğŸ“Š æŒ‡æ ‡æ”¶é›†

### 1. åŸºç¡€æŒ‡æ ‡æ”¶é›†å™¨

```rust
use std::collections::HashMap;
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::sync::RwLock;

#[derive(Debug, Clone)]
pub struct Metrics {
    pub counters: Arc<RwLock<HashMap<String, AtomicU64>>>,
    pub gauges: Arc<RwLock<HashMap<String, AtomicU64>>>,
    pub histograms: Arc<RwLock<HashMap<String, Histogram>>>,
}

impl Metrics {
    pub fn new() -> Self {
        Self {
            counters: Arc::new(RwLock::new(HashMap::new())),
            gauges: Arc::new(RwLock::new(HashMap::new())),
            histograms: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    pub async fn increment_counter(&self, name: &str, value: u64) {
        let mut counters = self.counters.write().await;
        counters
            .entry(name.to_string())
            .or_insert_with(|| AtomicU64::new(0))
            .fetch_add(value, Ordering::SeqCst);
    }

    pub async fn set_gauge(&self, name: &str, value: u64) {
        let mut gauges = self.gauges.write().await;
        gauges
            .entry(name.to_string())
            .or_insert_with(|| AtomicU64::new(0))
            .store(value, Ordering::SeqCst);
    }

    pub async fn record_histogram(&self, name: &str, value: f64) {
        let mut histograms = self.histograms.write().await;
        histograms
            .entry(name.to_string())
            .or_insert_with(|| Histogram::new())
            .record(value);
    }
}
```

### 2. RED æŒ‡æ ‡å®ç°

```rust
#[derive(Debug)]
pub struct RedMetrics {
    metrics: Metrics,
}

impl RedMetrics {
    pub fn new() -> Self {
        Self {
            metrics: Metrics::new(),
        }
    }

    // Rate: è¯·æ±‚ç‡
    pub async fn record_request(&self, endpoint: &str, method: &str) {
        let metric_name = format!("requests_total{{endpoint=\"{}\",method=\"{}\"}}", endpoint, method);
        self.metrics.increment_counter(&metric_name, 1).await;
    }

    // Error: é”™è¯¯ç‡
    pub async fn record_error(&self, endpoint: &str, method: &str, status_code: u16) {
        let metric_name = format!("errors_total{{endpoint=\"{}\",method=\"{}\",status=\"{}\"}}", 
                                 endpoint, method, status_code);
        self.metrics.increment_counter(&metric_name, 1).await;
    }

    // Duration: æŒç»­æ—¶é—´
    pub async fn record_duration(&self, endpoint: &str, method: &str, duration: Duration) {
        let metric_name = format!("request_duration_seconds{{endpoint=\"{}\",method=\"{}\"}}", 
                                 endpoint, method);
        self.metrics.record_histogram(&metric_name, duration.as_secs_f64()).await;
    }
}
```

### 3. USE æŒ‡æ ‡å®ç°

```rust
#[derive(Debug)]
pub struct UseMetrics {
    metrics: Metrics,
}

impl UseMetrics {
    pub fn new() -> Self {
        Self {
            metrics: Metrics::new(),
        }
    }

    // Utilization: åˆ©ç”¨ç‡
    pub async fn record_cpu_utilization(&self, node_id: &str, utilization: f64) {
        let metric_name = format!("cpu_utilization{{node=\"{}\"}}", node_id);
        self.metrics.set_gauge(&metric_name, (utilization * 100.0) as u64).await;
    }

    pub async fn record_memory_utilization(&self, node_id: &str, utilization: f64) {
        let metric_name = format!("memory_utilization{{node=\"{}\"}}", node_id);
        self.metrics.set_gauge(&metric_name, (utilization * 100.0) as u64).await;
    }

    // Saturation: é¥±å’Œåº¦
    pub async fn record_queue_length(&self, queue_name: &str, length: usize) {
        let metric_name = format!("queue_length{{queue=\"{}\"}}", queue_name);
        self.metrics.set_gauge(&metric_name, length as u64).await;
    }

    // Error: é”™è¯¯ç‡
    pub async fn record_system_error(&self, component: &str, error_type: &str) {
        let metric_name = format!("system_errors_total{{component=\"{}\",type=\"{}\"}}", 
                                 component, error_type);
        self.metrics.increment_counter(&metric_name, 1).await;
    }
}
```

## ğŸ“ æ—¥å¿—èšåˆ

### 1. ç»“æ„åŒ–æ—¥å¿—é…ç½®

```rust
use tracing::{info, warn, error, debug};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init_logging() {
    tracing_subscriber::registry()
        .with(EnvFilter::from_default_env())
        .with(tracing_subscriber::fmt::layer()
            .json()
            .with_current_span(true)
            .with_span_list(false)
        )
        .init();
}

// ä½¿ç”¨ç¤ºä¾‹
pub async fn process_request(request: &Request) -> Result<Response, Error> {
    let span = tracing::info_span!("process_request", 
                                  request_id = %request.id,
                                  user_id = %request.user_id);
    let _enter = span.enter();

    info!("å¼€å§‹å¤„ç†è¯·æ±‚");
    
    match validate_request(request).await {
        Ok(_) => {
            debug!("è¯·æ±‚éªŒè¯é€šè¿‡");
            let response = execute_request(request).await?;
            info!("è¯·æ±‚å¤„ç†å®Œæˆ", duration_ms = response.duration.as_millis());
            Ok(response)
        }
        Err(e) => {
            warn!("è¯·æ±‚éªŒè¯å¤±è´¥", error = %e);
            Err(e)
        }
    }
}
```

### 2. æ—¥å¿—æ”¶é›†å™¨

```rust
use std::sync::mpsc;
use std::thread;

pub struct LogCollector {
    sender: mpsc::Sender<LogEntry>,
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct LogEntry {
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub level: String,
    pub message: String,
    pub fields: HashMap<String, serde_json::Value>,
    pub span_context: Option<SpanContext>,
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct SpanContext {
    pub trace_id: String,
    pub span_id: String,
}

impl LogCollector {
    pub fn new() -> Self {
        let (sender, receiver) = mpsc::channel();
        
        // å¯åŠ¨æ—¥å¿—å¤„ç†çº¿ç¨‹
        thread::spawn(move || {
            Self::process_logs(receiver);
        });
        
        Self { sender }
    }

    fn process_logs(receiver: mpsc::Receiver<LogEntry>) {
        let mut batch = Vec::new();
        let mut last_flush = std::time::Instant::now();
        
        for log_entry in receiver {
            batch.push(log_entry);
            
            // æ‰¹é‡å¤„ç†æˆ–å®šæ—¶åˆ·æ–°
            if batch.len() >= 100 || last_flush.elapsed() > Duration::from_secs(5) {
                Self::flush_logs(&mut batch);
                last_flush = std::time::Instant::now();
            }
        }
    }

    fn flush_logs(batch: &mut Vec<LogEntry>) {
        if batch.is_empty() {
            return;
        }

        // å‘é€åˆ°æ—¥å¿—èšåˆç³»ç»Ÿ
        for log_entry in batch.drain(..) {
            Self::send_to_aggregator(log_entry);
        }
    }

    fn send_to_aggregator(log_entry: LogEntry) {
        // å‘é€åˆ° Elasticsearch, Splunk, æˆ–å…¶ä»–æ—¥å¿—èšåˆç³»ç»Ÿ
        let json = serde_json::to_string(&log_entry).unwrap();
        println!("LOG: {}", json);
    }

    pub fn collect_log(&self, entry: LogEntry) {
        self.sender.send(entry).unwrap_or_else(|_| {
            eprintln!("æ—¥å¿—æ”¶é›†å™¨å·²å…³é—­");
        });
    }
}
```

## ğŸ” é“¾è·¯è¿½è¸ª

### 1. åˆ†å¸ƒå¼è¿½è¸ªå™¨

```rust
use std::sync::Arc;
use uuid::Uuid;

#[derive(Debug, Clone)]
pub struct DistributedTracer {
    service_name: String,
    collector_endpoint: String,
    spans: Arc<RwLock<Vec<Span>>>,
}

#[derive(Debug, Clone)]
pub struct Span {
    pub trace_id: String,
    pub span_id: String,
    pub parent_span_id: Option<String>,
    pub operation_name: String,
    pub start_time: chrono::DateTime<chrono::Utc>,
    pub end_time: Option<chrono::DateTime<chrono::Utc>>,
    pub tags: HashMap<String, String>,
    pub logs: Vec<SpanLog>,
}

#[derive(Debug, Clone)]
pub struct SpanLog {
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub fields: HashMap<String, String>,
}

impl DistributedTracer {
    pub fn new(service_name: String, collector_endpoint: String) -> Self {
        Self {
            service_name,
            collector_endpoint,
            spans: Arc::new(RwLock::new(Vec::new())),
        }
    }

    pub fn start_span(&self, operation_name: &str, parent_span: Option<&Span>) -> Span {
        let trace_id = parent_span
            .map(|p| p.trace_id.clone())
            .unwrap_or_else(|| Uuid::new_v4().to_string());
        
        let span_id = Uuid::new_v4().to_string();
        let parent_span_id = parent_span.map(|p| p.span_id.clone());

        Span {
            trace_id,
            span_id,
            parent_span_id,
            operation_name: operation_name.to_string(),
            start_time: chrono::Utc::now(),
            end_time: None,
            tags: HashMap::new(),
            logs: Vec::new(),
        }
    }

    pub fn finish_span(&self, mut span: Span) {
        span.end_time = Some(chrono::Utc::now());
        
        let spans = self.spans.clone();
        tokio::spawn(async move {
            let mut spans = spans.write().await;
            spans.push(span);
        });
    }

    pub fn add_tag(&self, span: &mut Span, key: &str, value: &str) {
        span.tags.insert(key.to_string(), value.to_string());
    }

    pub fn add_log(&self, span: &mut Span, fields: HashMap<String, String>) {
        span.logs.push(SpanLog {
            timestamp: chrono::Utc::now(),
            fields,
        });
    }

    pub async fn export_spans(&self) -> Result<(), Error> {
        let spans = {
            let mut spans = self.spans.write().await;
            spans.drain(..).collect::<Vec<_>>()
        };

        if spans.is_empty() {
            return Ok(());
        }

        // å‘é€åˆ°è¿½è¸ªæ”¶é›†å™¨
        self.send_to_collector(spans).await?;
        Ok(())
    }

    async fn send_to_collector(&self, spans: Vec<Span>) -> Result<(), Error> {
        let client = reqwest::Client::new();
        let payload = serde_json::to_string(&spans)?;
        
        let response = client
            .post(&self.collector_endpoint)
            .header("Content-Type", "application/json")
            .body(payload)
            .send()
            .await?;

        if !response.status().is_success() {
            return Err(Error::CollectorError(format!("HTTP {}", response.status())));
        }

        Ok(())
    }
}
```

## ğŸš¨ å‘Šè­¦ç³»ç»Ÿ

### 1. å‘Šè­¦è§„åˆ™å¼•æ“

```rust
use std::collections::HashMap;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AlertRule {
    pub id: String,
    pub name: String,
    pub condition: AlertCondition,
    pub severity: AlertSeverity,
    pub cooldown: Duration,
    pub notification_channels: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertCondition {
    CounterThreshold {
        metric_name: String,
        threshold: u64,
        operator: ComparisonOperator,
        time_window: Duration,
    },
    GaugeThreshold {
        metric_name: String,
        threshold: f64,
        operator: ComparisonOperator,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ComparisonOperator {
    GreaterThan,
    LessThan,
    GreaterThanOrEqual,
    LessThanOrEqual,
    Equal,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertSeverity {
    Critical,
    Warning,
    Info,
}

pub struct AlertEngine {
    rules: HashMap<String, AlertRule>,
    metrics: Metrics,
    notification_service: NotificationService,
    alert_history: AlertHistory,
}

impl AlertEngine {
    pub fn new(metrics: Metrics, notification_service: NotificationService) -> Self {
        Self {
            rules: HashMap::new(),
            metrics,
            notification_service,
            alert_history: AlertHistory::new(),
        }
    }

    pub fn add_rule(&mut self, rule: AlertRule) {
        self.rules.insert(rule.id.clone(), rule);
    }

    pub async fn evaluate_rules(&self) -> Result<(), Error> {
        for rule in self.rules.values() {
            if self.should_evaluate_rule(rule).await {
                match self.evaluate_condition(&rule.condition).await {
                    Ok(true) => {
                        self.trigger_alert(rule).await?;
                    }
                    Ok(false) => {
                        // æ¡ä»¶ä¸æ»¡è¶³ï¼Œé‡ç½®å‘Šè­¦çŠ¶æ€
                        self.reset_alert_state(rule).await;
                    }
                    Err(e) => {
                        tracing::error!("è¯„ä¼°å‘Šè­¦è§„åˆ™å¤±è´¥: {}", e);
                    }
                }
            }
        }
        Ok(())
    }

    async fn should_evaluate_rule(&self, rule: &AlertRule) -> bool {
        if let Some(last_alert) = self.alert_history.get_last_alert(&rule.id).await {
            return last_alert.timestamp + rule.cooldown < chrono::Utc::now();
        }
        true
    }

    async fn evaluate_condition(&self, condition: &AlertCondition) -> Result<bool, Error> {
        match condition {
            AlertCondition::CounterThreshold { metric_name, threshold, operator, time_window } => {
                let value = self.metrics.get_counter(metric_name).await
                    .ok_or_else(|| Error::MetricNotFound(metric_name.clone()))?;
                Ok(self.compare_values(value as f64, *threshold as f64, operator))
            }
            AlertCondition::GaugeThreshold { metric_name, threshold, operator } => {
                let value = self.metrics.get_gauge(metric_name).await
                    .ok_or_else(|| Error::MetricNotFound(metric_name.clone()))?;
                Ok(self.compare_values(value as f64, *threshold, operator))
            }
        }
    }

    fn compare_values(&self, value: f64, threshold: f64, operator: &ComparisonOperator) -> bool {
        match operator {
            ComparisonOperator::GreaterThan => value > threshold,
            ComparisonOperator::LessThan => value < threshold,
            ComparisonOperator::GreaterThanOrEqual => value >= threshold,
            ComparisonOperator::LessThanOrEqual => value <= threshold,
            ComparisonOperator::Equal => (value - threshold).abs() < f64::EPSILON,
        }
    }

    async fn trigger_alert(&self, rule: &AlertRule) -> Result<(), Error> {
        let alert = Alert {
            id: Uuid::new_v4().to_string(),
            rule_id: rule.id.clone(),
            severity: rule.severity.clone(),
            message: format!("å‘Šè­¦è§¦å‘: {}", rule.name),
            timestamp: chrono::Utc::now(),
            metadata: HashMap::new(),
        };

        // è®°å½•å‘Šè­¦å†å²
        self.alert_history.record_alert(alert.clone()).await;

        // å‘é€é€šçŸ¥
        for channel in &rule.notification_channels {
            self.notification_service.send_alert(channel, &alert).await?;
        }

        tracing::warn!("å‘Šè­¦è§¦å‘", rule_id = %rule.id, severity = ?rule.severity);
        Ok(())
    }
}
```

## ğŸ“ˆ ä»ªè¡¨æ¿é…ç½®

### 1. Prometheus é›†æˆ

```rust
use prometheus::{Counter, Histogram, Gauge, Registry, TextEncoder, Encoder};

pub struct PrometheusMetrics {
    pub registry: Registry,
    pub request_counter: Counter,
    pub request_duration: Histogram,
    pub active_connections: Gauge,
}

impl PrometheusMetrics {
    pub fn new() -> Result<Self, Error> {
        let registry = Registry::new();
        
        let request_counter = Counter::new(
            "http_requests_total",
            "Total number of HTTP requests"
        )?;
        
        let request_duration = Histogram::new(
            "http_request_duration_seconds",
            "HTTP request duration in seconds"
        )?;
        
        let active_connections = Gauge::new(
            "active_connections",
            "Number of active connections"
        )?;

        registry.register(Box::new(request_counter.clone()))?;
        registry.register(Box::new(request_duration.clone()))?;
        registry.register(Box::new(active_connections.clone()))?;

        Ok(Self {
            registry,
            request_counter,
            request_duration,
            active_connections,
        })
    }

    pub fn record_request(&self, method: &str, endpoint: &str, status_code: u16, duration: Duration) {
        self.request_counter
            .with_label_values(&[method, endpoint, &status_code.to_string()])
            .inc();
        
        self.request_duration
            .with_label_values(&[method, endpoint])
            .observe(duration.as_secs_f64());
    }

    pub fn set_active_connections(&self, count: i64) {
        self.active_connections.set(count);
    }

    pub fn export_metrics(&self) -> Result<String, Error> {
        let metric_families = self.registry.gather();
        let encoder = TextEncoder::new();
        let mut buffer = Vec::new();
        encoder.encode(&metric_families, &mut buffer)?;
        
        Ok(String::from_utf8(buffer)?)
    }
}
```

### 2. Grafana ä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "title": "åˆ†å¸ƒå¼ç³»ç»Ÿç›‘æ§ä»ªè¡¨æ¿",
    "panels": [
      {
        "title": "è¯·æ±‚ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "å“åº”æ—¶é—´",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P95 å“åº”æ—¶é—´"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P50 å“åº”æ—¶é—´"
          }
        ]
      },
      {
        "title": "é”™è¯¯ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m]) * 100",
            "legendFormat": "é”™è¯¯ç‡ (%)"
          }
        ]
      }
      ,
      {
        "title": "Raft é€‰ä¸¾æ¬¡æ•°",
        "type": "stat",
        "targets": [
          { "expr": "rate(raft_leader_elections_total[5m])", "legendFormat": "é€‰ä¸¾/ç§’" }
        ]
      },
      {
        "title": "å‰¯æœ¬è½å (ms)",
        "type": "graph",
        "targets": [
          { "expr": "replica_lag_ms", "legendFormat": "{{node}}" }
        ]
      }
    ]
  }
}
```

## ğŸ”— ç›¸å…³èµ„æº

- [å¿«é€Ÿå¼€å§‹æŒ‡å—](../QUICKSTART.md)
- [ç³»ç»Ÿè®¾è®¡æœ€ä½³å®è·µ](../design/BEST_PRACTICES.md)
- [æ€§èƒ½ä¼˜åŒ–æŠ€å·§](../performance/OPTIMIZATION.md)
- [æµ‹è¯•ç­–ç•¥](../testing/README.md)
- [å¸¸è§é™·é˜±ä¸è°ƒè¯•](../PITFALLS.md)

## ğŸ†˜ è·å–å¸®åŠ©

- **GitHub Issues**: [æŠ¥å‘Šé—®é¢˜](https://github.com/your-org/c20_distributed/issues)
- **Discussions**: [è®¨è®ºäº¤æµ](https://github.com/your-org/c20_distributed/discussions)
- **Stack Overflow**: [æŠ€æœ¯é—®ç­”](https://stackoverflow.com/questions/tagged/c20-distributed)

---

**å…¨é¢ç›‘æ§ï¼** ğŸš€ å»ºç«‹å®Œå–„çš„å¯è§‚æµ‹æ€§ä½“ç³»ï¼Œç¡®ä¿åˆ†å¸ƒå¼ç³»ç»Ÿçš„ç¨³å®šè¿è¡Œå’Œå¿«é€Ÿæ•…éšœå®šä½ã€‚
